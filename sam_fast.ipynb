{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c42dc31-fd9e-4fec-8763-c85e0dd40b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -q --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu121\n",
    "!pip3 install -q git+https://github.com/pytorch-labs/segment-anything-fast.git\n",
    "!pip3 install -q triton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0faaede7-06fc-47bf-80c4-1626f0460c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datashape: (24, 128, 128, 3)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: CUDA driver version is insufficient for CUDA runtime version\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nDevice-side assertions were explicitly omitted for this error check; the error probably arose while initializing the DSA handlers.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m sam \u001b[38;5;241m=\u001b[39m sam_model_registry[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvit_h\u001b[39m\u001b[38;5;124m\"\u001b[39m](checkpoint\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel/sam_vit_h_4b8939.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m mask_generator \u001b[38;5;241m=\u001b[39m SamAutomaticMaskGenerator(sam)\n\u001b[0;32m---> 11\u001b[0m masks \u001b[38;5;241m=\u001b[39m \u001b[43mmask_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_vis\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/segment_anything_fast/automatic_mask_generator.py:170\u001b[0m, in \u001b[0;36mSamAutomaticMaskGenerator.generate\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;124;03mGenerates masks for the given image.\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;124;03m         the mask, given in XYWH format.\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;66;03m# Generate masks\u001b[39;00m\n\u001b[0;32m--> 170\u001b[0m mask_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_masks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# Filter small disconnected regions and holes in masks\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_mask_region_area \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/segment_anything_fast/automatic_mask_generator.py:213\u001b[0m, in \u001b[0;36mSamAutomaticMaskGenerator._generate_masks\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m    211\u001b[0m data \u001b[38;5;241m=\u001b[39m MaskData()\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m crop_box, layer_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(crop_boxes, layer_idxs):\n\u001b[0;32m--> 213\u001b[0m     crop_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_crop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcrop_box\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morig_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m     data\u001b[38;5;241m.\u001b[39mcat(crop_data)\n\u001b[1;32m    216\u001b[0m \u001b[38;5;66;03m# Remove duplicate masks between crops\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/segment_anything_fast/automatic_mask_generator.py:255\u001b[0m, in \u001b[0;36mSamAutomaticMaskGenerator._process_crop\u001b[0;34m(self, image, crop_box, crop_layer_idx, orig_size)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(all_points), process_batch_size):\n\u001b[1;32m    254\u001b[0m     some_points \u001b[38;5;241m=\u001b[39m all_points[i:i\u001b[38;5;241m+\u001b[39mprocess_batch_size]\n\u001b[0;32m--> 255\u001b[0m     batch_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43msome_points\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcropped_im_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcrop_box\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morig_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m     data\u001b[38;5;241m.\u001b[39mcat(batch_data)\n\u001b[1;32m    257\u001b[0m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrles\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m mask_to_rle_pytorch_2(data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmasks\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/segment_anything_fast/automatic_mask_generator.py:291\u001b[0m, in \u001b[0;36mSamAutomaticMaskGenerator._process_batch\u001b[0;34m(self, all_points, im_size, crop_box, orig_size)\u001b[0m\n\u001b[1;32m    288\u001b[0m     in_points \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mas_tensor(transformed_points) \u001b[38;5;66;03m#, device=self.predictor.device)\u001b[39;00m\n\u001b[1;32m    289\u001b[0m     nt_in_points\u001b[38;5;241m.\u001b[39mappend(in_points)\n\u001b[0;32m--> 291\u001b[0m nt_in_points \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnested\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnested_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnt_in_points\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjagged\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpin_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mdevice, non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    292\u001b[0m \u001b[38;5;66;03m# The call to prod is a workaround to share jagged sizes between two NestedTensors.\u001b[39;00m\n\u001b[1;32m    293\u001b[0m nt_in_labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones_like(nt_in_points, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mint)\u001b[38;5;241m.\u001b[39mprod(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nested/__init__.py:236\u001b[0m, in \u001b[0;36mnested_tensor\u001b[0;34m(tensor_list, dtype, layout, device, requires_grad, pin_memory)\u001b[0m\n\u001b[1;32m    234\u001b[0m     nt\u001b[38;5;241m.\u001b[39mrequires_grad_(requires_grad)\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pin_memory:\n\u001b[0;32m--> 236\u001b[0m         nt \u001b[38;5;241m=\u001b[39m \u001b[43mnt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpin_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m nt\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nested/_internal/nested_tensor.py:233\u001b[0m, in \u001b[0;36mNestedTensor.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39mDisableTorchFunctionSubclass():\n\u001b[0;32m--> 233\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nested/_internal/nested_tensor.py:217\u001b[0m, in \u001b[0;36mNestedTensor.__torch_dispatch__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    215\u001b[0m fn \u001b[38;5;241m=\u001b[39m lookup_jagged(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 217\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(func)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nested/_internal/ops.py:182\u001b[0m, in \u001b[0;36mregister_func.<locals>.wrapper.<locals>.get_inner.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    181\u001b[0m     check_schema(schema_str, func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43maten_op\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nested/_internal/ops.py:762\u001b[0m, in \u001b[0;36m_pin_memory_default\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    756\u001b[0m _, new_kwargs \u001b[38;5;241m=\u001b[39m normalize_function(\n\u001b[1;32m    757\u001b[0m     func, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs, normalize_to_only_use_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    758\u001b[0m )\n\u001b[1;32m    760\u001b[0m inp \u001b[38;5;241m=\u001b[39m new_kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 762\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m NestedTensor(\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnew_kwargs\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mextract_kwargs(inp))\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/_ops.py:630\u001b[0m, in \u001b[0;36mOpOverload.__call__\u001b[0;34m(self_, *args, **kwargs)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(self_, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# use `self_` to avoid naming collide with aten ops arguments that\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# are named \"self\". This way, all the aten ops can be called by kwargs.\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mself_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: CUDA driver version is insufficient for CUDA runtime version\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nDevice-side assertions were explicitly omitted for this error check; the error probably arose while initializing the DSA handlers."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from segment_anything_fast import SamAutomaticMaskGenerator, sam_model_registry\n",
    "\n",
    "data = np.load('data/0.npy')\n",
    "print(\"Datashape: \" + str(data.shape))\n",
    "data_vis = torch.from_numpy(data).permute(0,3, 1, 2)\n",
    "\n",
    "sam = sam_model_registry[\"vit_h\"](checkpoint=\"model/sam_vit_h_4b8939.pth\")\n",
    "mask_generator = SamAutomaticMaskGenerator(sam)\n",
    "masks = mask_generator.generate(data_vis[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475fc265-2c05-43cc-a39f-20a254ae24bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
